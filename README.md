# <center> Awesome-Large-Audio-Models
## ‚ú®‚ú® Awesome-Large-Audio-Models ‚ú®‚ú®

Welcome to Awesome-Large-Audio-Models, your go-to resource for the latest advancements, papers, and benchmarks in the world of cutting-edge audio models. This repository is meticulously curated for researchers, developers, and enthusiasts passionate about pushing the boundaries of audio processing and understanding.

### üìö Latest Papers

Stay at the forefront of audio model research with these recent papers:

1. **"AudioPaLM: A Large Language Model That Can Speak and Listen"**  
    - *Authors*: *Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zal√°n Borsos, F√©lix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo Velimiroviƒá, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank*
    - *[PDF](https://arxiv.org/abs/2306.12925)*
2. **"Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities"**
    - *Authors*: *Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou,* [Xipeng Qiu](https://arxiv.org/search/cs?searchtype=author&query=Qiu,+X)
    - *[PDF](https://arxiv.org/abs/2305.11000)  [Code](https://github.com/0nutation/SpeechGPT)*
3. **"SeamlessM4T‚ÄîMassively Multilingual & Multimodal Machine Translation"**
    - *Authors*: *Seamless Communication, Lo√Øc Barrault, Yu-An Chung, Mariano Cora Meglioli, David Dale, Ning Dong, Paul-Ambroise Duquenne, Hady Elsahar, Hongyu Gong, Kevin Heffernan, John Hoffman, Christopher Klaiber, Pengwei Li, Daniel Licht, Jean Maillard, Alice Rakotoarison, Kaushik Ram Sadagopan, Guillaume Wenzek, Ethan Ye, Bapi Akula, Peng-Jen Chen, Naji El Hachem, Brian Ellis, Gabriel Mejia Gonzalez, Justin Haaheim, Prangthip Hansanti, Russ Howes, Bernie Huang, Min-Jae Hwang, Hirofumi Inaguma, Somya Jain, Elahe Kalbassi, Amanda Kallet, Ilia Kulikov, Janice Lam, Daniel Li, Xutai Ma, Ruslan Mavlyutov, Benjamin Peloquin, Mohamed Ramadan, Abinesh Ramakrishnan, Anna Sun, Kevin Tran, Tuan Tran, Igor Tufanov, Vish Vogeti, Carleigh Wood, Yilin Yang, Bokai Yu, Pierre Andrews, Can Balioglu, Marta R. Costa-juss√†, Onur Celebi, Maha Elbayad, Cynthia Gao, Francisco Guzm√°n, Justine Kao, Ann Lee, Alexandre Mourachko, Juan Pino, Sravya Popuri, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Paden Tomasello, Changhan Wang, Jeff Wang, Skyler Wang*
    - *[PDF](https://arxiv.org/abs/2308.11596) [Code](https://github.com/facebookresearch/seamless_communication)*
4. ‚Äú**PolyVoice: Language Models for Speech to Speech Translation**‚Äù
    - *Authors*: *Qianqian Dong, Zhiying Huang, Qiao Tian, Chen Xu, Tom Ko, Yunlong Zhao, Siyuan Feng, Tang Li, Kexin Wang, Xuxin Cheng, Fengpeng Yue, Ye Bai, Xi Chen, Lu Lu, Zejun Ma, Yuping Wang, Mingxuan Wang, Yuxuan Wang*
    - *[PDF](https://arxiv.org/abs/2306.02982)*
5. **"Unified Model for Image, Video, Audio and Language Tasks"**
    - *Authors*: *Mustafa Shukor, Corentin Dancette, Alexandre Rame, Matthieu Cord*
    - *[PDF](https://arxiv.org/abs/2307.16184) [Code](https://github.com/mshukor/UnIVAL)*
    

### üî• Speech to Text

Stay up-to-date with the latest advancements in speech-to-text models:

1. **"Robust Speech Recognition via Large-Scale Weak Supervision"**
    - *Authors*: *Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever*
    - *[PDF](https://arxiv.org/abs/2212.04356) [Code](https://github.com/openai/whisper)*
2. **"Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages"**
    - *Authors*: *Yu Zhang, Wei Han, James Qin, Yongqiang Wang, Ankur Bapna, Zhehuai Chen, Nanxin Chen, Bo Li, Vera Axelrod, Gary Wang, Zhong Meng, Ke Hu, Andrew Rosenberg, Rohit Prabhavalkar, Daniel S. Park, Parisa Haghani, Jason Riesa, Ginger Perng, Hagen Soltau, Trevor Strohman, Bhuvana Ramabhadran, Tara Sainath, Pedro Moreno, Chung-Cheng Chiu, Johan Schalkwyk, Fran√ßoise Beaufays, Yonghui Wu*
    - *[PDF](https://arxiv.org/abs/2303.01037)*
3.   **‚ÄúPrompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition‚Äù**
    - *Authors*: *Yuang Li, Yu Wu, Jinyu Li, Shujie Liu*
    - *[PDF](https://arxiv.org/abs/2306.16007)*
4. **‚ÄúExploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study‚Äù**
    - *Authors*: *Zeping Min, Jinbo Wang*
    - *[PDF](https://arxiv.org/abs/2307.06530)*
5. **‚ÄúOn decoder-only architecture for speech-to-text and large language model integration‚Äù**
    - *Authors*: *Jian Wu, Yashesh Gaur, Zhuo Chen, Long Zhou, Yimeng Zhu, Tianrui Wang, Jinyu Li, Shujie Liu, Bo Ren, Linquan Liu, Yu Wu*
    - *[PDF](https://arxiv.org/abs/2307.03917)*
6. **‚ÄúAdapting Large Language Model with Speech for Fully Formatted End-to-End Speech Recognition‚Äù**
    - *Authors*: *Shaoshi Ling, Yuxuan Hu, Shuangbei Qian, Guoli Ye, Yao Qian, Yifan Gong, Ed Lin, Michael Zeng*
    - *[PDF](https://arxiv.org/abs/2307.08234)*
7. ‚Äú**Prompting Large Language Models with Speech Recognition Abilities**‚Äù
    - *Authors*: *Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Junteng Jia, Yuan Shangguan, Ke Li, Jinxi Guo, Wenhan Xiong, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, Mike Seltzer*
    - *[PDF](https://arxiv.org/abs/2307.11795)*
8. **‚ÄúSemantic Segmentation with Bidirectional Language Models Improves Long-form ASR‚Äù**
    - *Authors*: *W. Ronny Huang, Hao Zhang, Shankar Kumar, Shuo-yiin Chang, Tara N. Sainath*
    - *[PDF](https://arxiv.org/abs/2305.18419)*

### ü™ó Audio Generation

1. **‚ÄúAudioLM: A Language Modeling Approach to Audio Generation‚Äù**
    - *Authors: Zal√°n Borsos, Rapha√´l Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi,Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, and Neil Zeghidour*
    - *[PDF](https://ieeexplore.ieee.org/abstract/document/10158503)*
2. ‚Äú**AudioGen: Textually Guided Audio Generation‚Äù**
    - *Authors: Felix Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre D√©fossez, Jade Copet, Devi Parikh, Yaniv Taigman, Yossi Adi*
    - *[PDF](https://arxiv.org/abs/2209.15352)*
3. **‚ÄúFoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model‚Äù**
    - *Authors: Ruiqing Xue, Yanqing Liu, Lei He, Xu Tan, Linquan Liu, Edward Lin, Sheng Zhao*
    - *[PDF](https://arxiv.org/abs/2303.02939)*
4. **‚ÄúText-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model‚Äù**
    - *Authors: Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, Soujanya Poria*
    - *[PDF](https://arxiv.org/abs/2304.13731)  [Code](https://github.com/declare-lab/tango)*
5. **‚ÄúWavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research‚Äù**
    - *Authors: Xinhao Mei, Chutong Meng, Haohe Liu, Qiuqiang Kong, Tom Ko, Chengqi Zhao, Mark D. Plumbley, Yuexian Zou, Wenwu Wang*
    - *[PDF](https://arxiv.org/abs/2303.17395)  [Code](https://github.com/XinhaoMei/WavCaps)*
6. **‚ÄúAudioLDM: Text-to-Audio Generation with Latent Diffusion Models‚Äù**
    - *Authors: Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley*
    - *[PDF](https://arxiv.org/abs/2301.12503) [Code](https://audioldm.github.io)*
7. **‚ÄúMake-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models‚Äù**
    - *Authors: Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, Zhou Zhao*
    - *[PDF](https://arxiv.org/abs/2301.12661)*
8. **‚ÄúLarge-scale unsupervised audio pre-training for video-to-speech synthesis‚Äù**
    - *Authors: Triantafyllos Kefalas, Yannis Panagakis, Maja Pantic*
    - *[PDF](https://arxiv.org/abs/2306.15464)*
9. **‚ÄúReVISE: Self-Supervised Speech Resynthesis With Visual Input for Universal and Generalized Speech Regeneration‚Äù**
    - *Authors: Wei-Ning Hsu, Tal Remez, Bowen Shi, Jacob Donley, Yossi Adi*
    - *[PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Hsu_ReVISE_Self-Supervised_Speech_Resynthesis_With_Visual_Input_for_Universal_and_CVPR_2023_paper.pdf)*

### üçª Cross-Modal Representation

1. **‚ÄúCLAP Learning Audio Concepts from Natural Language Supervision‚Äù**
    - *Authors: Benjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, Huaming Wang*
    - *[PDF](https://ieeexplore.ieee.org/abstract/document/10095889)*
2. **‚ÄúSpeechCLIP: Integrating Speech with Pre-Trained Vision and Language Model‚Äù**
    - *Authors: Yi-Jen Shih, Hsuan-Fu Wang, Heng-Jui Chang, Layne Berry, Hung-yi Lee, David Harwath*
    - *[PDF](https://ieeexplore.ieee.org/abstract/document/10022954)*
3. ‚Äú**BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing**‚Äù 
    - *Authors: Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang*
    - *[PDF](https://arxiv.org/abs/2309.00916)*
4. **‚ÄúVideo-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding‚Äù**
    - *Authors: Hang Zhang,¬†Xin Li,¬†Lidong Bing*
    - *[PDF](https://arxiv.org/abs/2306.02858) [Code](https://github.com/DAMO-NLP-SG/Video-LLaMA)*
5. **‚ÄúMusic Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning‚Äù**
    - *Authors: Shansong Liu,¬†Atin Sakkeer Hussain,¬†Chenshuo Sun,¬†Ying Shan*
    - *[PDF](https://arxiv.org/abs/2308.11276)*

### üìà Benchmarks

Track the progress of large audio models through benchmark performance metrics:

- **ASR Leaderboard**: Monitor the latest results in automatic speech recognition (ASR) across diverse datasets, evaluating the accuracy, speed, and memory efficiency of various models.
- **Speech Synthesis Quality**: Explore benchmark scores for evaluating the quality and naturalness of synthesized speech, ensuring your applications deliver a premium auditory experience.
- **Audio Classification Challenges**: Stay up-to-date with ongoing audio classification challenges and assess model performance across different domains, from environmental sounds to musical genres.

### üåê Community Contributions

We encourage the audio research community to actively contribute to this repository by adding relevant papers, benchmark results, or tools that can benefit the community at large. Let's collaboratively advance the field of large audio models!

### üôå Acknowledgments

We'd like to express our gratitude to all the researchers and developers who tirelessly work on improving audio models and sharing their findings with the community. This repository stands as a testament to your dedication.

### üìÑ Citation

If you find this resource helpful in your research, please consider citing us:

```
@github{Awesome-Large-Audio-Models,
  title = {Awesome-Large-Audio-Models},
  author = {Your Name},
  year = {2023},
  url = {<https://github.com/yourusername/Awesome-Large-Audio-Models>},
  note = {Your specific note (optional)}
}

```

### üåü Let's Elevate Audio Research Together!

Join us in the quest to push the boundaries of large audio models. Together, we can create remarkable advancements in audio processing and understanding. Explore, contribute, and innovate! üöÄüéßüîä
